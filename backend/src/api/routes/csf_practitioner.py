from typing import List, Optional
from datetime import datetime
import uuid

from fastapi import APIRouter
from pydantic import BaseModel, Field

from src.api.models.compliance_models import RegulatorySource
from src.api.models.decision import RegulatoryReference
import src.autocomply.domain.csf_copilot as csf_copilot
from src.autocomply.domain.csf_practitioner import (
    CsDecisionStatus,
    PractitionerCsfDecision,
    PractitionerCsfForm,
    describe_practitioner_csf_decision,
    evaluate_practitioner_csf,
)
from src.autocomply.domain.rag_regulatory_explain import RegulatoryRagAnswer
from src.autocomply.domain.submissions_store import (
    get_submission_store,
    SubmissionPriority,
)
from src.autocomply.domain.trace import generate_trace_id
from src.utils.logger import get_logger


router = APIRouter(
    prefix="/csf/practitioner",
    tags=["csf_practitioner"],
)

logger = get_logger(__name__)

# In-memory submission store (replace with database in production)
# TODO: Replace with proper database persistence
SUBMISSION_STORE: dict = {}


default_copilot_question = (
    "Explain to a verification specialist what this Practitioner CSF decision "
    "means, what is missing, and what is required next."
)


DEFAULT_COPILOT_QUESTION = default_copilot_question


class PractitionerCopilotRequest(PractitionerCsfForm):
    question: Optional[str] = Field(
        default=None,
        description="Optional custom question for the copilot explanation.",
    )


class PractitionerCopilotResponse(BaseModel):
    """
    API response model for the Practitioner CSF form copilot.

    Tests expect the following top-level keys to be present:
    - status
    - reason
    - missing_fields
    - regulatory_references
    - rag_explanation
    - artifacts_used
    - rag_sources
    """

    status: CsDecisionStatus
    reason: str
    missing_fields: List[str] = Field(default_factory=list)
    regulatory_references: List[RegulatoryReference] = Field(default_factory=list)
    rag_explanation: str
    artifacts_used: List[str] = Field(default_factory=list)
    rag_sources: List[RegulatorySource] = Field(default_factory=list)


@router.post("/evaluate", response_model=PractitionerCsfDecision)
async def evaluate_practitioner_csf_endpoint(
    form: PractitionerCsfForm,
) -> PractitionerCsfDecision:
    """
    Evaluate a Practitioner Controlled Substance Form and return a decision.
    """
    decision = evaluate_practitioner_csf(form)

    logger.info(
        "Practitioner CSF decision evaluated",
        extra={
            "decision_status": decision.status,
            "missing_fields": decision.missing_fields,
        },
    )

    return decision


@router.post("/form-copilot", response_model=PractitionerCopilotResponse)
async def practitioner_form_copilot(
    form: PractitionerCopilotRequest,
) -> PractitionerCopilotResponse:
    """
    Practitioner Form Copilot endpoint backed by regulatory RAG.
    """

    # Always run the core decision engine first
    decision = evaluate_practitioner_csf(form)

    # Default reason if RAG is not used
    base_reason = (
        "Based on the information provided and the modeled rules for the "
        "Practitioner CSF vertical, AutoComply AI considers this request "
        "approved to proceed with shipment."
    )
    reason = base_reason

    # Default RAG stub text (matches tests' expected fallback phrase)
    rag_explanation = (
        "Regulatory RAG explanation is currently unavailable. In a full environment, "
        "this endpoint would pull in Practitioner CSF guidance and provide a "
        "specialist-friendly summary for the question: "
        f"{form.question or DEFAULT_COPILOT_QUESTION}"
    )

    stub_source = RegulatorySource(
        id="csf_practitioner_form",
        title="Practitioner CSF form",
        snippet=describe_practitioner_csf_decision(form, decision),
    )
    rag_sources: List[RegulatorySource] = [stub_source]
    artifacts_used: List[str] = ["csf_practitioner_form"]
    regulatory_references: List[RegulatoryReference] = [
        RegulatoryReference(id="csf_practitioner_form", label="Practitioner CSF form")
    ]

    try:
        rag_answer: RegulatoryRagAnswer = csf_copilot.explain_csf_practitioner_decision(
            decision={**decision.model_dump(), "form": form.model_dump()},
            question=form.question or DEFAULT_COPILOT_QUESTION,
            regulatory_references=decision.regulatory_references,
        )

        if rag_answer.answer:
            # Keep `reason` as the stable summary; put RAG text into rag_explanation
            rag_explanation = rag_answer.answer

        if rag_answer.regulatory_references:
            regulatory_references = [
                RegulatoryReference(
                    id=getattr(ref, "id", ref),
                    label=getattr(ref, "label", getattr(ref, "id", str(ref))),
                )
                for ref in rag_answer.regulatory_references
            ]

        if rag_answer.artifacts_used:
            artifacts_used = rag_answer.artifacts_used

        if rag_answer.sources:
            rag_sources = [
                RegulatorySource.model_validate(
                    src.model_dump() if hasattr(src, "model_dump") else src
                )
                for src in rag_answer.sources
            ]
    except Exception:
        logger.exception(
            "Failed to generate practitioner CSF copilot explanation",
            extra={
                "engine_family": "csf",
                "decision_type": "csf_practitioner",
                "account_number": getattr(form, "account_number", None),
            },
        )
        # Failure path: leave `reason` as the stable narrative and keep the
        # fallback `rag_explanation` defined above so tests can assert on it.

    return PractitionerCopilotResponse(
        status=decision.status,
        reason=reason,
        missing_fields=list(decision.missing_fields or []),
        regulatory_references=regulatory_references,
        rag_explanation=rag_explanation,
        artifacts_used=artifacts_used,
        rag_sources=rag_sources,
    )


class SubmissionResponse(BaseModel):
    """Response for CSF submission."""
    submission_id: str
    status: str
    created_at: str
    decision_status: Optional[CsDecisionStatus] = None
    reason: Optional[str] = None


@router.post("/submit", response_model=SubmissionResponse)
async def submit_practitioner_csf(
    form: PractitionerCsfForm,
) -> SubmissionResponse:
    """
    Submit a Practitioner CSF for internal verification tracking.
    
    This endpoint:
    1. Evaluates the CSF using the decision engine
    2. Creates a submission record in the unified submissions store
    3. Generates trace_id for trace replay in Compliance Console
    4. Returns submission ID and status for user confirmation
    """
    # Run decision engine
    decision = evaluate_practitioner_csf(form)
    
    # Generate trace ID for replay
    trace_id = generate_trace_id()
    
    # Determine priority based on decision status
    priority = SubmissionPriority.HIGH if decision.status == CsDecisionStatus.BLOCKED else SubmissionPriority.MEDIUM
    
    # Create human-readable title and subtitle
    practitioner_name = getattr(form, 'prescriber_name', None) or form.account_number
    title = f"Practitioner CSF â€“ {practitioner_name}"
    
    if decision.status == CsDecisionStatus.BLOCKED:
        subtitle = f"Blocked: {decision.reason}"
    elif decision.status == CsDecisionStatus.NEEDS_REVIEW:
        subtitle = f"Review required: {decision.reason}"
    else:
        subtitle = f"Submitted for verification"
    
    # Get store and create submission
    store = get_submission_store()
    submission = store.create_submission(
        csf_type="practitioner",
        tenant=getattr(form, 'tenant', 'practitioner-default'),
        title=title,
        subtitle=subtitle,
        trace_id=trace_id,
        payload={
            "form": form.model_dump(),
            "decision": decision.model_dump(),
        },
        decision_status=decision.status.value if decision.status else None,
        risk_level="High" if decision.status == CsDecisionStatus.BLOCKED else "Medium",
        priority=priority,
    )
    
    logger.info(
        "Practitioner CSF submitted for verification",
        extra={
            "submission_id": submission.submission_id,
            "trace_id": trace_id,
            "decision_status": decision.status,
            "account_number": form.account_number,
        },
    )
    
    return SubmissionResponse(
        submission_id=submission.submission_id,
        status="submitted",
        created_at=submission.created_at,
        decision_status=decision.status,
        reason=decision.reason,
    )


@router.get("/submissions/{submission_id}", response_model=dict)
async def get_submission(submission_id: str) -> dict:
    """
    Retrieve a previously submitted Practitioner CSF by ID.
    
    Returns full submission details including form data, decision, and metadata.
    """
    submission = SUBMISSION_STORE.get(submission_id)
    
    if not submission:
        return {
            "error": "Submission not found",
            "submission_id": submission_id,
        }
    
    return submission
